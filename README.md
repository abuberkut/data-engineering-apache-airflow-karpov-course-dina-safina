# Введение в ETL 

<details>
<summary>Требования</summary>
  
- Базовый уровень Python
- Здравый смысл
- Понимание проектирования DWH (чтобы не облажаться при построении архитектуры), инструменты для реализации ETL (чтобы правильно забирать данные или складывать в хранилище), много практики построения ETL
</details>

<details>
<summary>1. Что такое ETL</summary>
  
  - Extract (CSV, DB Table, API…)
  - Transform (with Python, deduplication, formats…)
  - Load (Insert in DWH), 
  - ELT - E + L (сырые данные сначала загружаются в хранилище), T
  1. Перенос данных из одного или нескольких источников в большое хранилище данных, он нужен не всегда (когда небольшой проект, 1-2 БД с репликами).
  2. Если данные хранятся в разных местах, то понадобится хранилище чтобы их анализировать, нужен ETL
</details>

<details>
<summary>2. Как правильно готовить ETL</summary>
  
    1. Принципы построения ETL
        1. Чистый код
        2. Простота
        3. Единообразие (Пайплана)
        4. Время выполнения пайплайна (если долго, то что-то не так)
        5. Меньше сетевого трафика
        6. Работа с репликой (чтобы не ломать мэйн БД)
        7. Оптимизация забора данных (БД индексы…)
        8. Партицирование
        9. Инкрементальный пересчет витрин (снепшоты)
        10. Загрузка всего без ограничений (сырые данные из источника - это лучше)
        11. Избавляться от неактуального (Аудит пайплайнов - оставлять только нужные)
        12. Идемпотентность (лучше использовать merge, чем insert)
        13. Аудиторский след (сырые данные хранить в DWH, чтобы в случае ошибки заново на месте пересчитать)
    2. Будьте готовы
        1. Отсутствие целостности (данные в источниках не всегда идеальны, несоответствия мелкие будут)
        2. Сетевые проблемы (идемпотентность должно решать эту проблему)
        3. Незапланированные изменения (в БД или АПИ,… ) 
        4. Пайплайны будут задерживаться (акции, память пайплайна заняли много) - контролировать важные пайплайны
        5. Данные из разных системах противоречивы (одна система хранит - дни, другая - сумму, другая - сумму фрода)
</details>

<details>
<summary>3. Обзор планировщиков (scheduler - запустить в нужный момент задачу)</summary>
  
    1. CRON
        1. «+» Максимально простой, «-» максимально простой
    2. Jenkins/gitlab CI
        1.  Предназначено больше для. CI/CD
    3. Написать свой (google, yandex,...)
    4. Платные - дорогие, нет доступа к коду, есть поддержка, визуальный редактор
    5. Опен сорс - бесплатно, можно посмотреть код, можно контрибютить, риск ошибок в коде (Apache Oozie, NiFi; Talend (Java), Luigi, Airflow - остальные на Python) 
</details>

<details>
<summary>4. Почему Airflow</summary>
  
    1. Open source
    2. Отличная документация
    3. Простий код на Python 
    4. Удобный UI
    5. Алертинг и мониторинг
    6. Интеграция с основными источниками
    7. Кастомизацию
    8. Масштабирование (Докер, кластеры)
    9. Большое комьюнити
</details>

# Знакомство с Airflow

<details>
<summary>1. История Airflow</summary>

    1. Октябрь 2014 - создание Airflow в Airbnb (Open source)
    2. Март 2016 - передали в Apache Incubator 
    3. Январь 2019 - top-level проект 
    4. Конец 2020 - Airflow 2.0
</details>
<details>
<summary>2. Основные поняти</summary>
  
    1. DAG (Directed Acyclic Graph) - однонаправленный ацикличный (без циклов) граф
        1. Каждая вершина - одна задача (Task)
        2. Ребра - зависимости между Task-ами
        3. Task
            1. Сущность Operator - выполняет конкретную задачу
            2. Сущность Sensor (special type of Operator) - дожидается выполнение события
            3. Сначала запускается таск, не имеющий предшественников, после его отработки выполняются те таски, которые зависят от предыдущего, до тех пор пока не доходят до последнего таска
            4. Таски объединяются в DAG по смыслу - ждем появление записи, забираем к себе, преобразовываем, отправляем уведомление о выполнении DAG-a
            5. DAG-ов может быть очень много
            6. Таски время от времени  падают (по какой-то причине), таск переходит в состояние «retry», перезапускается (по умолчанию 3 раза). После 3-ей безуспешной попытки таск переходит в состояние «failed», а последующие за ним таски в состояние «upstream-failed», потом DAG переходит в состояние «failed», получаем уведомление или видим в UI
        4. После объявления DAG-а, можем поставить его на расписание (под капотом Airflow - cron), можем использовать alias-ы для указывание времени (@none, @once, @daily…) 
</details>
<details>
<summary>3. Компоненты Airflow</summary>
  
    1. Webserver 
        1. Показать внешний вид DAG-а (DAG Directory)
        2. Статус Выполнения DAG-а (Metadata)
        3. Перезапуск
        4. Отладка
    2. Scheduler (Планировщик)
        1. Анализирует DAG-и по умолчанию 1 раз в минуту (DAG Directory)
        2. Создаёт DAG Run - экземпляр DAG-а и характеризуется параметром «execution_date» (начала предыдущего периода, если запуск 15 сентября, то значение будет 14-ое) (в момент когда должен запуститься DAG)
        3. Создаёт Task Instance - каждая задача генерируется в отдельный Task Instance и этот instance привязывается к DAG-у, для них тоже прикидывается «execution_date»
        4. Ставит таски в очередь
        5. Для выполнения активных задач планировщик использует указанный у нас в настройках «executor»
    3. Executor 
        1. Механизм с помощью которого запускаются Task Instance-ы
        2. Работает в одной связке с планировщиком, то есть когда запускаете процесс планировщика, то процесс executor-a запускается в том же самом процессе
        3. Категории 
            1. Локальные (исполняются на той же машине, на котором есть Scheduler)
                1. SequentialExecutor - последовательно запускает задачи и на время их выполнения приостанавливает планировщик, другие задачи не ставятся в очередь - неудобно, по умолчанию airflow подсказывает заменить его на хотя бы LocalExecutor
                2. LocalExecutor - на каждую задачу запускает отдельный процесс, позволяет параллельно запускать столько задач, сколько позволяет генерировать машина. Тоже не рекомендуется на вроде, так как низкоустойчивый - если машина остановится, то и Airflow остановится 
                3. DebugExecutor - нужен только для того, чтобы запускать DAG-и из среды разработки
            2. Нелокальные (могут запускать таски удаленно, scheduler на другой машине)
                1. CeletyExecutor
                    1. Может иметь несколько worker-ов на разных машинах, требует дополнительные настройки брокер-сообщений (Redis, RabbitMQ)
                    2. Позволяет масштабировать Airfow подключением нового worker-а
                    3. При подключении нового worker-а часть задач переходят к нему, если с одним worker-ом что-то пошло не так, то эта задача переадресует на другие работающие worker-ы
                2. DaskExecutor (тоже самое только билиотекой Dask)
                3. KubernetesExecutor - на каждый TaskInstance запускает новый worker на отдельном pod-e в k8. «+» Появляется динамическое распределение ресурсов, «-» - необходимо уметь поднять и настроить k8
                4. CeleryKubernetesExecutor - одноввременно держит 2 executor-a и в зависимости от Task (параметра queue) выполняется либо 1-ым, либо 2-ым executor-ом
                5. Custom
    4. Worker (Обработчик задач)
            1. Процесс, в котором исполняются задачи
            2. В зависимости от executor-а может быть запущен локально на той же машине что и scheduler или на другой машине
    5. METADATA DATABASE (Информация о состоянии всех пайплайнов)
            1. DAG (Инфо об абстрактном DAG-е)
            2. DAG Run (Инфо о конкретных запусках DAG-a - DAG Run-ов)
            3. Task Instance (Инфо когда запустился, как завершился, сколько попыток,…)
            4. Variable (Глобальные переменные)
            5. Connection
            6. XCom
            7. ….
</details>
